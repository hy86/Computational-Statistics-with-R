library(mvtnorm)

### Function for data generation from scenario 1
dg2 <- function(ss) {
  sig <- matrix(c(1, -.5, -.5, 1), 2, 2)
  tr <- rbind(rmvnorm(ss, mean = c(0,0), sigma = sig),
              rmvnorm(ss, mean = c(1,1), sigma = sig))
  tr <- cbind(rep(c(0,1), each = ss), tr)
  tr <- data.frame(tr)
  names(tr) <- c("class", "X1", "X2")
  tr
}
d2 <- dg2(5000)
plot(d2[,2:3], col = d2$class + 3, pch = 1)

pDens1 <- function(xy, clss = "green")
{
  ### This function takes an argument xy and applies the density for 
  ### class green or class blue
  
  if(clss == "green") {mm <- c(0,0); ss <- matrix(c(1, -.5, -.5, 1), 2, 2)}
  if(clss == "blue") {mm <- c(1,1); ss <- matrix(c(1, -.5, -.5, 1), 2, 2)}
  out <- dmvnorm(x = xy, mean = mm, sigma = ss)
  out
}

dom <- seq(-5, 5, .1)
grid <- expand.grid(dom, dom)
dfgrid <- data.frame(grid)
names(dfgrid) <- c("X1", "X2")

### Create a vector to store results
outputG <- numeric(dim(dfgrid)[1])
outputB <- numeric(dim(dfgrid)[1])

### Run the function for each x,y pair in the domain "dom"
for (i in 1:dim(dfgrid)[1])
{
  outputG[i] <- pDens1(xy = dfgrid[i,], clss = "green")
  outputB[i] <- pDens1(xy = dfgrid[i,], clss = "blue")
}

### Posterior probabilities
posts <- outputG*(1/2) / (outputG*(1/2) + outputB*(1/2))

### Bayes decision boundary for dg4.
pmat <- matrix(posts, length(dom))
contour(dom, dom, pmat, levels=0.5, labels="", xlab="", ylab="",
        axes=FALSE, add = TRUE, lwd = 3, col = "red")

### Function for data generation from scenario 2
dg5 <- function(ss) {
  sig <- diag(2)
  tr <- rbind(rmvnorm(ss, mean = c(0,0), sigma = sig),
              rmvnorm(ss, mean = c(1,1), sigma = sig))
  tr <- data.frame(tr)
  names(tr) <- c( "X1", "X2")
  attach(tr)
  probs <- exp(X1 + X2 - X1^2 + X2^2 - X1*X2) / 
    (1 + exp(X1 + X2 - X1^2 + X2^2 - X1*X2))
  inds <- rbinom(n = length(probs), size = 1, prob = probs)
  detach(tr)
  tr <- cbind(inds, tr)
  tr <- data.frame(tr)
  names(tr) <- c("class", "X1", "X2")
  tr
}
d5 <- dg5(5000)
plot(d5[,2:3], col = d5$class + 3, pch = 1)

### Bayes decision boundary for dg5.
dom <- seq(-4, 6, .1)
grid <- expand.grid(dom, dom)
dfgrid <- data.frame(grid)
names(dfgrid) <- c("X1", "X2")
attach(dfgrid)
pgrid <- exp(X1 + X2 - X1^2 + X2^2 - X1*X2) / 
  (1 + exp(X1 + X2 - X1^2 + X2^2 - X1*X2))
detach(dfgrid)
pmat <- matrix(pgrid, length(dom))
contour(dom, dom, pmat, levels=0.5, labels="", xlab="", ylab="",
        axes=FALSE, add = TRUE, lwd = 3, col = "red")

### Function to get overall error from a confusion table
err <- function(v1, v2) {
  tab <- table(v1, v2)
  err <- (tab/sum(tab))[1,2] + (tab/sum(tab))[2,1]
  err
}

### Function to get the error rates from 5 models
simFun <- function(dat, test) {
  ### The argument dat is a data frame generated by one of the 
  ### "dg" functions defined above.
  
  ### Logistic regression with only linear predictors
  lr1 <- glm(class ~ X1 + X2, data = dat, family = "binomial")
  lr1P <- predict(lr1, newdata = test, type = "response") # probabilities
  lr1C <- as.numeric(lr1P >= .5)                           # 0s and 1s
  ### LDA
  lda <- lda(class ~ X1 + X2, data = dat)
  ldaC <- predict(lda, newdata = test)$class
  ldaC <- as.numeric(as.character(ldaC))
  ### QDA
  qda <- qda(class ~ X1 + X2, data = dat)
  qdaC <- predict(qda, newdata = test)$class
  qdaC <- as.numeric(as.character(qdaC))
  ### KNN-1
  knn1 <- knn(train = dat[,2:3], cl = dat[,1], test = test[,2:3], 
               k = 1, prob = TRUE)
  knn1 <- as.numeric(as.character(knn1))
  ### KNN-10
  knn10 <- knn(train = dat[,2:3], cl = dat[,1], test = test[,2:3], 
              k = 10, prob = TRUE)
  knn10 <- as.numeric(as.character(knn10))
  errs <- c(err(lr1C, test[,1]), 
            err(ldaC, test[,1]), err(qdaC, test[,1]),
            err(knn1, test[,1]), err(knn10, test[,1]) )
  errs
}



### Load packages
library(MASS) # for LDA and QDA
library(class) # for KNN

###############################################################################
### SCENARIO 2 ################################################################
###############################################################################

### Set seed for reproducibility
set.seed(294850)

### Generate testing set
test2 <- dg2(10000)

### How many replications?
R <- 100
### Create a placeholder to store output
out2 <- matrix(0, R, 5)

### Generate 100 training data sets. For each data set determine
### the error rate on the test set using each method
for (i in 1:R) {
  out2[i,] <- simFun(dat = dg2(20), test = test2)
}

out2 <- data.frame(out2)
names(out2) <- c("LR1", "LDA", "QDA", "KNN1", "KNN10")
boxplot(out2, col = c(3, 2, 3, 4, 4), lwd = 3, main = "SCENARIO 1")

###############################################################################
### SCENARIO 5 ################################################################
###############################################################################

### Set seed for reproducibility
set.seed(222222)

### Generate testing set
test5 <- dg5(10000)

### How many replications?
R <- 100
### Create a placeholder to store output
out5 <- matrix(0, R, 5)

### Generate 100 training data sets. For each data set determine
### the error rate on the test set using each method
for (i in 1:R) {
  out5[i,] <- simFun(dat = dg5(50), test = test5)
}

out5 <- data.frame(out5)
names(out5) <- c("LR1", "LDA", "QDA", "KNN1", "KNN10")
boxplot(out5, col = c( 3, 2, 3, 4, 4), lwd = 3, main = "SCENARIO 2")